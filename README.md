# Emotion-Detector-From-Audio-Input

Speech emotion recognition is a growing field
within human-computer interaction, enabling machines to
understand user emotions through voice. This paper introduces
a neural network-based system that classifies emotional states
from speech using audio features like MFCCs, chroma vectors,
and mel spectrograms. Using the RAVDESS dataset and an
optimized multi-layer perceptron architecture, the system
achieves 74.48% accuracy in detecting four emotions:
calmness, happiness, fearfulness, and disgust. The findings
highlight the significance of combining spectral and prosodic
cues to accurately capture emotional nuances.

![image](https://github.com/user-attachments/assets/479a5633-3a79-4bd4-b090-98882219d061)

